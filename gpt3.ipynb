{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "client = OpenAI(api_key='your key here')\n",
    "\n",
    "# Load prompts from a JSONL file\n",
    "def load_prompts(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return [json.loads(line) for line in file]\n",
    "\n",
    "op_prompts = load_prompts('prompts_datasets/op_test_gpt.jsonl')\n",
    "pairs_prompts = load_prompts('prompts_datasets/pairs_test_gpt.jsonl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T04:03:44.331935Z",
     "start_time": "2024-10-03T04:03:44.200761Z"
    }
   },
   "id": "f02ac414ef772fff",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get GPT 3.5 responses with various prompting methods"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "913cc041b3698f42"
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to send requests and gather responses\n",
    "def get_responses(prompts, instruction, desc=\"Getting GPT3.5 Responses: \"):\n",
    "    responses = []\n",
    "    for prompt in tqdm(prompts, desc=desc):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                      model=\"gpt-3.5-turbo\",\n",
    "                      messages=[\n",
    "                          {\"role\":\"system\", \"content\":instruction},\n",
    "                          prompt['body']['messages'][1]\n",
    "                      ],\n",
    "                    max_completion_tokens=prompt['body']['max_tokens'],\n",
    "                    )\n",
    "            responses.append(response)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing prompt {prompt['custom_id']}: {e}\")\n",
    "            responses.append(None)\n",
    "    return responses"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T04:03:45.660287Z",
     "start_time": "2024-10-03T04:03:45.639035Z"
    }
   },
   "id": "69a03815dbdf6e2a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get ops responses (malleability tasks)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acd05cb2e7638a59"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Knowledge about telling the malleability of the opinion, extracted from the paper: Winning Arguments: Interaction Dynamics and Persuasion Strategies in Good-faith Online Discussions\n",
    "knowledge_op = \"Hints: 1. Use of First-Person Pronouns: The use of first-person singular pronouns (e.g., I, me) is strongly correlated with malleability while the use of first-person plural pronouns (e.g., we, us) is more associated with resistant opinions. 2. Dominance in Language: Higher dominance in the language used by the OP correlates with malleability. 3. Calm Tone: calmer, less emotional language in the original post is associated with malleability. 4. Valence (Emotional Positivity): Higher valence, which reflects more positive emotional tone, indicates malleability. 5.Formatting: Posts that are well-organized, with more paragraphs and formatting such as bolds and bullet lists, are correlated with malleable opinions.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T04:03:48.490229Z",
     "start_time": "2024-10-03T04:03:48.468631Z"
    }
   },
   "id": "63064cb52d330927"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting GPT3.5 Responses: 100%|██████████| 200/200 [01:44<00:00,  1.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get responses of Original Posts from GPT3.5\n",
    "directly_predict = \"You're a semantic analyst. Now I will show you a person's opinion statement. We know that the person publicly announced his/her argument and encouraged other people to challenge it. Judging from the speech style and lexical features, do you think he/she is resistant or malleable to persuasion? Answer with 'malleable' or 'resistant'.\"\n",
    "predict_then_explain = \"You're a semantic analyst. Now I will show you a person's opinion statement. We know that the person publicly announced his/her argument and encouraged other people to challenge it. Judging from the speech style and lexical features, do you think he/she is resistant or malleable to persuasion? Answer with 'malleable' or 'resistant' and explain your answer. Response with the following format: Prediction: resistant/malleable \\n Explanation: briefly explain here.\"\n",
    "explain_then_predict = \"You're a semantic analyst. Now I will show you a person's opinion statement. We know that the person publicly announced his/her argument and encouraged other people to challenge it. Judging from the speech style and lexical features, do you think he/she is resistant or malleable to persuasion? First briefly explain your analysis and then give your answer with resistant/malleable. Response with the following format: Explanation: briefly explain here. \\n  Prediction: resistant/malleable\"\n",
    "\n",
    "op_responses_direct = get_responses(op_prompts, directly_predict)\n",
    "op_responses_pred_explain = get_responses(op_prompts, predict_then_explain)\n",
    "op_responses_explain_pred = get_responses(op_prompts, explain_then_predict)\n",
    "op_responses_with_knowledge = get_responses(op_prompts, directly_predict + knowledge_op)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T21:06:14.212137Z",
     "start_time": "2024-10-02T21:04:30.156211Z"
    }
   },
   "id": "b85ddc576407e332"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get pairs responses(persuasion tasks)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3832c50d7680e2d5"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Knowledge on how to persuade the poster, extracted from the paper: Winning Arguments: Interaction Dynamics and Persuasion Strategies in Good-faith Online Discussions\n",
    "knowledge_pairs = \"Hint: 1. Language Dissimilarity with Original Post: Persuasive replies use different content words but match in stopwords 2.Reply Length: Longer replies tend to be more persuasive, as they can convey more information and elaborate on points effectively. 3. Language Dissimilarity with Original Post: Persuasive replies use different content words but match in stopwords. 4. Links and Evidence: Including links as evidence in an argument increases the chances of persuasion. 5. Calmer Tone: Replies that use calmer, less intense language are more likely to persuade, as they come across as more composed. 6. Positive Emotion and Sentiment: Persuasive replies include a mix of positive and negative sentiment.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-02T17:41:49.509679Z"
    }
   },
   "id": "cb9aa35543cfe6be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T01:06:13.915404Z",
     "start_time": "2024-10-03T01:06:13.902194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get responses of Pairs(op, reply1, reply2) from GPT3.5\n",
    "directly_predict = \"This is a conversation from an online discussion community. The first was a poster who posted an opinion, and the next two replies were each trying to convince the poster to revise his opinion. The two responses were similar, but one managed to convince the poster and the other didn't. Now judge which response succeeded in persuading. Answer only with first/second.\"\n",
    "predict_then_explain = \"This is a conversation from an online discussion community. The first was a poster who posted an opinion, and the next two replies were each trying to convince the poster to revise his opinion. The two responses were similar, but one managed to convince the poster and the other didn't. Now first judge which response succeeded in persuading and then explain your analysis very briefly. Response with the following format: Prediction: answer only with first or second \\n Explanation: briefly explain here.\"\n",
    "explain_then_predict = \"This is a conversation from an online discussion community. The first was a poster who posted an opinion, and the next two replies were each trying to convince the poster to revise his opinion. The two responses were similar, but one managed to convince the poster and the other didn't. Now first show your analysis very briefly and then judge which response succeeded in persuading. Response with the following format: Explanation: briefly analyse here. \\n Prediction: answer only with first or second\"\n",
    "\n",
    "pairs_responses_direct = get_responses(pairs_prompts, directly_predict)\n",
    "pairs_responses_pred_explain = get_responses(pairs_prompts, predict_then_explain)\n",
    "pairs_responses_explain_pred = get_responses(pairs_prompts, explain_then_predict)\n",
    "pairs_responses_with_knowledge = get_responses(pairs_prompts, directly_predict + knowledge_pairs)"
   ],
   "id": "10629898ab7633f4",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Two Stage method (on persuasion tasks)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e90ab03d4d4a7c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:56:54.891406Z",
     "start_time": "2024-10-02T17:42:06.572828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "instruction_1 = f\"This is a conversation from an online discussion community. The first was a poster who posted an opinion, and the next two replies were each trying to convince the poster to revise his opinion. Analyze the persuasiveness of the two replies respectively in two paragraphs with the following format: First Reply: your analysis here.\\n Second Reply: your analysis here.\\n Note only analysis, not conclusions. \\n {knowledge_pairs}\"\n",
    "instruction_2 = f\"You're a semantic analyst. The following two paragraphs are analysis on the persuasiveness of two replies. These replies are from an online discussion community that are trying to convince the original poster to revise its opinion. Based on these analysis, which reply do you think that successfully persuaded the original poster? \\n Answer only with first or second.\\n {knowledge_pairs}\"\n",
    "# Implement a two stage prompting: \n",
    "# 1) ask GPT to analyse the linguistic features of the two replies but do not make conclusions. \n",
    "# 2) ask GPT to evaluate previous analysis and make conclusions. \n",
    "# Both stages have knowledge instilled.\n",
    "def get_two_stage_responses(prompts, instruction_1, instruction_2):\n",
    "    stage_one_responses = get_responses(prompts, instruction_1, desc=\"Getting GPT3.5 Responses(1st stage): \")\n",
    "    stage_one_responses = [res.choices[0].message.content for res in stage_one_responses]\n",
    "    stage_two_responses = []\n",
    "    for prompt in tqdm(stage_one_responses, desc=\"Getting GPT3.5 Responses(2nd stage): \"):\n",
    "        response = client.chat.completions.create(\n",
    "                  model=\"gpt-3.5-turbo\",\n",
    "                  messages=[\n",
    "                      {\"role\":\"system\", \"content\":instruction_2},\n",
    "                      {\"role\": \"user\", \"content\":prompt},\n",
    "                  ],\n",
    "                max_completion_tokens=1000,\n",
    "                )\n",
    "        stage_two_responses.append(response)\n",
    "    return stage_two_responses\n",
    "\n",
    "paris_two_stage_responses = get_two_stage_responses(pairs_prompts, instruction_1, instruction_2)"
   ],
   "id": "a488f109a070fbfc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting GPT3.5 Responses(1st stage): 100%|██████████| 200/200 [13:23<00:00,  4.02s/it]\n",
      "Getting GPT3.5 Responses(2nd stage): 100%|██████████| 200/200 [01:24<00:00,  2.36it/s]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Two Stage method (on malleability tasks)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c88eae4f6789b938"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting GPT3.5 Responses(1st stage): 100%|██████████| 200/200 [06:44<00:00,  2.02s/it]\n",
      "Getting GPT3.5 Responses(2nd stage): 100%|██████████| 200/200 [01:30<00:00,  2.21it/s]\n"
     ]
    }
   ],
   "source": [
    "instruction_1 = f\"This is post from an online discussion community. The person openly stats his/her opinion and encourage others to challenge him/her. Now read the post and identify the speech style and lexical features that may indicate the extent of malleability of poster's opinion. Briefly report your analysis\\n Note you only identify these style and features, don't make any conclusions about them. \\n {knowledge_op}\"\n",
    "instruction_2 = f\"You're a semantic analyst. The following is an analysis on the extent of malleability of a poster's opinion. Based on these analysis, do you think the poster is resistant or malleable to persuasion? \\n Answer only with resistant or malleable.\\n {knowledge_op}\"\n",
    "# Implement a two stage prompting: \n",
    "# 1) ask GPT to analyse the linguistic features of the two replies but do not make conclusions. \n",
    "# 2) ask GPT to evaluate previous analysis and make conclusions. \n",
    "# Both stages have knowledge instilled.\n",
    "def get_two_stage_responses(prompts, instruction_1, instruction_2):\n",
    "    stage_one_responses = get_responses(prompts, instruction_1, desc=\"Getting GPT3.5 Responses(1st stage): \")\n",
    "    stage_one_responses = [res.choices[0].message.content for res in stage_one_responses]\n",
    "    stage_two_responses = []\n",
    "    for prompt in tqdm(stage_one_responses, desc=\"Getting GPT3.5 Responses(2nd stage): \"):\n",
    "        response = client.chat.completions.create(\n",
    "                  model=\"gpt-3.5-turbo\",\n",
    "                  messages=[\n",
    "                      {\"role\":\"system\", \"content\":instruction_2},\n",
    "                      {\"role\": \"user\", \"content\":prompt},\n",
    "                  ],\n",
    "                max_completion_tokens=1000,\n",
    "                )\n",
    "        stage_two_responses.append(response)\n",
    "    return stage_two_responses\n",
    "\n",
    "op_two_stage_responses = get_two_stage_responses(op_prompts, instruction_1, instruction_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T04:32:45.273253Z",
     "start_time": "2024-10-03T04:24:30.574304Z"
    }
   },
   "id": "b4e532609dfe9e68"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73787f013b314b1c"
  },
  {
   "cell_type": "code",
   "source": [
    "def prediction_accuracy(responses, file_path, test_n_sample=200, method=\"direct\"):\n",
    "    gpt_predictions = []\n",
    "    if method == \"direct\":\n",
    "        for res in responses:\n",
    "            gpt_predictions.append(res.choices[0].message.content.lower()[:1])\n",
    "    else:\n",
    "        for res in responses:\n",
    "            pred = res.choices[0].message.content.lower()\n",
    "            start_point = pred.find(\"prediction: \") + len(\"prediction: \")\n",
    "            if method == \"predict_then_explain\":\n",
    "                pred = pred[start_point: start_point + 1]\n",
    "            elif method == \"explain_then_predict\":\n",
    "                pred = pred[start_point: start_point + 1]\n",
    "            gpt_predictions.append(pred)\n",
    "    \n",
    "    def check_pred(preds):\n",
    "        n_mismatches = 0\n",
    "        for i, p in (enumerate(preds)):\n",
    "            if p not in ['f', 's']:\n",
    "                if p not in ['m', 'r']:\n",
    "                    n_mismatches += 1\n",
    "        if n_mismatches:\n",
    "            print(f\"{n_mismatches}/{len(preds)} \"\n",
    "              f\"of the predictions are not in correct format! \"\n",
    "              f\"They will not be included in counting accuracy.\")\n",
    "        return n_mismatches\n",
    "    n_mismatch = check_pred(gpt_predictions)\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        truths = [json.loads(line)[\"output\"][:1] for line in f][:test_n_sample]\n",
    "    scores = [1 if gpt_predictions[j] == truths[j] else 0 for j in range(len(truths))]\n",
    "    \n",
    "    return (sum(scores) - n_mismatch) / (len(truths) - n_mismatch)\n",
    "\n",
    "def z_test(n_sample, accuracy_1, accuracy_2):\n",
    "    import numpy as np\n",
    "    from scipy.stats import norm\n",
    "    pooled = (accuracy_1 * n_sample + accuracy_2 * n_sample) / (n_sample * 2)\n",
    "    z_score = (accuracy_1 - accuracy_2) / np.sqrt(pooled * (1 - pooled) * 2 / n_sample)\n",
    "    p_value = norm.sf(abs(z_score)) * 2\n",
    "    return p_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T04:32:45.305207Z",
     "start_time": "2024-10-03T04:32:45.295934Z"
    }
   },
   "id": "8daeb90383375fbc",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "## OPs Accuracies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fadecc85850bb29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T21:06:45.888928Z",
     "start_time": "2024-10-02T21:06:45.877097Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/200 of the predictions are not in correct format! They will not be included in accuracy.\n",
      "Accuracy for direct prediction with knowledge with GPT-3.5 turbo is 0.438\n"
     ]
    }
   ],
   "execution_count": 6,
   "source": [
    "file_path = \"finetune_llama3_1/finetune_datasets/op_test_alpaca.jsonl\"\n",
    "n_sample = len(op_responses_with_knowledge)\n",
    "\n",
    "op_accuracy_direct = prediction_accuracy(op_responses_direct, file_path)\n",
    "op_accuracy_pred_explain = prediction_accuracy(op_responses_pred_explain,\n",
    "                                               file_path,\n",
    "                                               method=\"predict_then_explain\")\n",
    "op_accuracy_explain_pred = prediction_accuracy(op_responses_explain_pred,\n",
    "                                               file_path,\n",
    "                                               method=\"explain_then_predict\")\n",
    "op_accuracy_with_knowledge = prediction_accuracy(op_responses_with_knowledge, file_path)\n",
    "p_2 = z_test(n_sample, op_accuracy_direct, op_accuracy_pred_explain)\n",
    "p_3 = z_test(n_sample, op_accuracy_direct, op_accuracy_explain_pred)\n",
    "\n",
    "print(f\"Accuracy for direct prediction with GPT-3.5 turbo is {op_accuracy_direct:.3f}.\")\n",
    "print(f\"Accuracy for predict-then-explain with GPT-3.5 turbo is {op_accuracy_pred_explain:.3f} with p-value: {p_2:.3f}\")\n",
    "print(f\"Accuracy for explain-then-predict with GPT-3.5 turbo is {op_accuracy_explain_pred:.3f} with p-value: {p_3:.3f}\")\n",
    "print(f\"Accuracy for direct prediction with knowledge with GPT-3.5 turbo is {op_accuracy_with_knowledge:.3f}\")"
   ],
   "id": "98bee9c8e31c3bae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pairs Accuracies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a312986a08729ec3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T03:22:51.582762Z",
     "start_time": "2024-10-01T03:22:51.547541Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for direct prediction with GPT-3.5 turbo is 0.485.\n",
      "Accuracy for direct prediction with GPT-3.5 turbo with knowledge is 0.530, with p-value: 0.368\n",
      "Accuracy for predict-then-explain with GPT-3.5 turbo is 0.470 with p-value: 0.764\n",
      "Accuracy for explain-then-predict with GPT-3.5 turbo is 0.455 with p-value: 0.548\n"
     ]
    }
   ],
   "execution_count": 100,
   "source": [
    "file_path = \"finetune_llama3_1/finetune_datasets/pairs_test_alpaca.jsonl\"\n",
    "n_sample = len(pairs_responses_direct)\n",
    "\n",
    "pairs_accuracy_direct = prediction_accuracy(pairs_responses_direct, file_path)\n",
    "pairs_accuracy_with_knowledge = prediction_accuracy(pairs_responses_with_knowledge, file_path)\n",
    "pairs_accuracy_pred_explain = prediction_accuracy(pairs_responses_pred_explain,\n",
    "                                               file_path,\n",
    "                                               method=\"predict_then_explain\")\n",
    "pairs_accuracy_explain_pred = prediction_accuracy(pairs_responses_explain_pred,\n",
    "                                               file_path,\n",
    "                                               method=\"explain_then_predict\")\n",
    "p_1 = z_test(n_sample, pairs_accuracy_direct, pairs_accuracy_with_knowledge)\n",
    "p_2 = z_test(n_sample, pairs_accuracy_direct, pairs_accuracy_pred_explain)\n",
    "p_3 = z_test(n_sample, pairs_accuracy_direct, pairs_accuracy_explain_pred)\n",
    "\n",
    "print(f\"Accuracy for direct prediction with GPT-3.5 turbo is {pairs_accuracy_direct:.3f}.\")\n",
    "print(f\"Accuracy for direct prediction with GPT-3.5 turbo with knowledge is {pairs_accuracy_with_knowledge:.3f}, with p-value: {p_1:.3f}\")\n",
    "print(f\"Accuracy for predict-then-explain with GPT-3.5 turbo is {pairs_accuracy_pred_explain:.3f} with p-value: {p_2:.3f}\")\n",
    "print(f\"Accuracy for explain-then-predict with GPT-3.5 turbo is {pairs_accuracy_explain_pred:.3f} with p-value: {p_3:.3f}\")"
   ],
   "id": "b37d46239074edb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Two Stage Accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6bc88a00859ca2d"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/200 of the predictions are not in correct format! They will not be included in accuracy.\n",
      "Accuracy for two stage prediction with GPT-3.5 turbo is 0.487.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"finetune_llama3/finetune_datasets/op_test_alpaca.jsonl\"\n",
    "n_sample = len(op_two_stage_responses)\n",
    "op_accuracy_two_stage = prediction_accuracy(op_two_stage_responses, file_path, test_n_sample=n_sample)\n",
    "print(f\"Accuracy for two stage prediction with GPT-3.5 turbo is {op_accuracy_two_stage:.3f}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T04:32:45.306025Z",
     "start_time": "2024-10-03T04:32:45.296192Z"
    }
   },
   "id": "f24f6c868b0bc7c3"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "file_path = \"finetune_llama3/finetune_datasets/pairs_test_alpaca.jsonl\"\n",
    "n_sample = len(paris_two_stage_responses)\n",
    "pairs_accuracy_two_stage = prediction_accuracy(paris_two_stage_responses, file_path, test_n_sample=n_sample)\n",
    "print(f\"Accuracy for two stage prediction with GPT-3.5 turbo is {pairs_accuracy_two_stage:.3f}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-02T21:08:21.756874Z"
    }
   },
   "id": "12fa7af882ae0fb2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate explanations for llama finetuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "461ca296f905f15a"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "def get_explanation_for_finetuning(prompts, truths, dataset=\"op\"):\n",
    "    responses = []\n",
    "    for prompt, truth in tqdm(zip(prompts, truths), \n",
    "                              desc=\"Getting GPT3.5 Responses: \", \n",
    "                              total=len(prompts)):\n",
    "        if dataset == \"op\":\n",
    "            if truth == \"malleable\":\n",
    "                insert = \"We know that he/she did get persuaded by some commentators. How might his/her speeching style and lexical features suggest he/she is malleable to persuasion?\"\n",
    "                \n",
    "            elif truth == \"resistant\":\n",
    "                insert = \"We know that he/she never get persuaded by others. How might his/her speeching style and lexical features suggest he/she is resistant to persuasion?\"\n",
    "                \n",
    "            instruction = f\"You're a semantic analyst. Now I will show you a person's opinion statement, who publicly announced his/her argument and encouraged other people to challenge it. {insert} Very briefly explain your analysis with no more than 2 paragraphs.\"\n",
    "        \n",
    "        elif dataset == \"pairs\":\n",
    "            instruction = f\"This is a conversation from an online discussion community. The first was a poster who posted an opinion, and the next two replies were each trying to convince the poster to revise his opinion. We know that the {truth} reply successfully persuaded the poster. How might his/her speeching style and lexical features suggest his/her persuasiveness? {knowledge_pairs} Very briefly explain your analysis with no more than 1000 tokens.\"\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                      model=\"gpt-3.5-turbo\",\n",
    "                      messages=[\n",
    "                          {\"role\":\"system\", \"content\": instruction},\n",
    "                          prompt['body']['messages'][1]\n",
    "                      ],\n",
    "                    max_completion_tokens=prompt['body']['max_tokens']\n",
    "                    )\n",
    "            responses.append(response)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing prompt {prompt['custom_id']}: {e}\")\n",
    "            responses.append(None)\n",
    "    return responses"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T03:24:44.427274Z",
     "start_time": "2024-10-01T03:24:44.419784Z"
    }
   },
   "id": "69b9ebf9fb986218"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "op_explanation_prompts = load_prompts(\"finetune_llama3/finetune_datasets/op_train_alpaca.jsonl\")\n",
    "op_truths = [line[\"output\"] for line in op_explanation_prompts]\n",
    "op_train_prompts = load_prompts(\"prompts_datasets/op_train_gpt.jsonl\")\n",
    "op_explanations = get_explanation_for_finetuning(op_train_prompts, op_truths, dataset=\"op\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bbf0b61f06aaa0e"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting GPT3.5 Responses: 100%|██████████| 1000/1000 [44:55<00:00,  2.70s/it] \n"
     ]
    }
   ],
   "source": [
    "pairs_explanation_prompts = load_prompts(\"finetune_llama3_1/finetune_datasets/pairs_train_alpaca.jsonl\")\n",
    "pairs_truths = [line[\"output\"] for line in pairs_explanation_prompts]\n",
    "pairs_train_prompts = load_prompts(\"prompts_datasets/pairs_train_gpt.jsonl\")\n",
    "pairs_explanations = get_explanation_for_finetuning(pairs_train_prompts, pairs_truths, dataset=\"pairs\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T04:14:04.873862Z",
     "start_time": "2024-10-01T03:29:09.191711Z"
    }
   },
   "id": "bf4ba53d57ec4ca0"
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "def create_jsonl(explanations, file_path):\n",
    "    with open(file_path, \"w\") as f:\n",
    "        for line in explanations:\n",
    "            content = line.choices[0].message.content\n",
    "            json.dump(content, f)\n",
    "            f.write(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T04:18:28.859531Z",
     "start_time": "2024-10-01T04:18:28.846481Z"
    }
   },
   "id": "fb7f443409af0693"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path = 'finetune_llama3/finetune_datasets/op_gpt_explanations.jsonl'\n",
    "create_jsonl(op_explanations, file_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "525ad0384181a466"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "file_path = 'finetune_llama3/finetune_datasets/pairs_gpt_explanations.jsonl'\n",
    "create_jsonl(pairs_explanations, file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T04:18:30.504272Z",
     "start_time": "2024-10-01T04:18:30.479791Z"
    }
   },
   "id": "25950c320d1cb56e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
