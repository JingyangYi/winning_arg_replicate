{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# load the data\n",
    "import tarfile\n",
    "import os.path\n",
    "import json\n",
    "import re\n",
    "from bz2 import BZ2File\n",
    "from urllib import request\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "fname = \"cmv.tar.bz2\"\n",
    "url = \"https://chenhaot.com/data/cmv/\" + fname\n",
    "\n",
    "# download if not exists\n",
    "if not os.path.isfile(fname):\n",
    "    f = BytesIO()\n",
    "    with request.urlopen(url) as resp, open(fname, 'wb') as f_disk:\n",
    "        data = resp.read()\n",
    "        f_disk.write(data)  # save to disk too\n",
    "        f.write(data)\n",
    "        f.seek(0)\n",
    "else:\n",
    "    f = open(fname, 'rb')\n",
    "\n",
    "\n",
    "tar = tarfile.open(fileobj=f, mode=\"r\")\n",
    "\n",
    "# Extract the file we are interested in\n",
    "\n",
    "train_fname = \"op_task/train_op_data.jsonlist.bz2\"\n",
    "test_fname = \"op_task/heldout_op_data.jsonlist.bz2\"\n",
    "\n",
    "train_bzlist = tar.extractfile(train_fname)\n",
    "\n",
    "# Deserialize the JSON list\n",
    "original_posts_train = [\n",
    "    json.loads(line.decode('utf-8'))\n",
    "    for line in BZ2File(train_bzlist)\n",
    "]\n",
    "\n",
    "test_bzlist = tar.extractfile(test_fname)\n",
    "\n",
    "original_posts_test = [\n",
    "    json.loads(line.decode('utf-8'))\n",
    "    for line in BZ2File(test_bzlist)\n",
    "]\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-27T13:19:21.085425Z",
     "start_time": "2024-09-27T13:15:34.378415Z"
    }
   },
   "id": "8b5cc763d3916cde"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def cleanup(cmv_post):\n",
    "    lines = [line for line in cmv_post.splitlines()\n",
    "             if not line.lstrip().startswith(\"&gt;\")\n",
    "             and not line.lstrip().startswith(\"____\")\n",
    "             and \"edit\" not in \" \".join(line.lower().split()[:2])\n",
    "            ]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def clean_dataset(dataset):\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i]['selftext'] = cleanup(dataset[i]['selftext'])\n",
    "    return dataset\n",
    "\n",
    "original_posts_train = clean_dataset(original_posts_train)\n",
    "original_posts_test = clean_dataset(original_posts_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-27T13:19:21.375268Z",
     "start_time": "2024-09-27T13:19:21.098345Z"
    }
   },
   "id": "aa1c56721fe78507"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               title  delta_label       name  \\\n0  CMV: I shouldn't get a job in this economic cl...        False  t3_2rpsl8   \n1  CMV: Iran has the right to develop nuclear wea...        False  t3_2rpfn7   \n2  CMV: The events in Paris suck...but the comic ...        False  t3_2rpevf   \n3  CMV: It is ok to hate a religion so long as yo...        False  t3_2rpcgr   \n4  CMV: There is no productive reason to have, \"U...        False  t3_2romiq   \n\n                                            selftext  \n0  I think the world is automating fast enough th...  \n1  First off, I do not believe that Iran *should*...  \n2  Please leave the footnote below the following ...  \n3  It seems to me that it is entirely justified t...  \n4  The, \"Under God\" line is actually a relatively...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>delta_label</th>\n      <th>name</th>\n      <th>selftext</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CMV: I shouldn't get a job in this economic cl...</td>\n      <td>False</td>\n      <td>t3_2rpsl8</td>\n      <td>I think the world is automating fast enough th...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CMV: Iran has the right to develop nuclear wea...</td>\n      <td>False</td>\n      <td>t3_2rpfn7</td>\n      <td>First off, I do not believe that Iran *should*...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CMV: The events in Paris suck...but the comic ...</td>\n      <td>False</td>\n      <td>t3_2rpevf</td>\n      <td>Please leave the footnote below the following ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CMV: It is ok to hate a religion so long as yo...</td>\n      <td>False</td>\n      <td>t3_2rpcgr</td>\n      <td>It seems to me that it is entirely justified t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CMV: There is no productive reason to have, \"U...</td>\n      <td>False</td>\n      <td>t3_2romiq</td>\n      <td>The, \"Under God\" line is actually a relatively...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(original_posts_train, columns=['title', 'delta_label', 'name', 'selftext'])\n",
    "df[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-27T13:19:21.432599Z",
     "start_time": "2024-09-27T13:19:21.389219Z"
    }
   },
   "id": "be4d99c198632a3"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def make_balanced_dataset(data, n_samples):\n",
    "    df = pd.DataFrame(data, columns=['title', 'delta_label', 'name', 'selftext'])\n",
    "    is_malleable = df['delta_label']\n",
    "    malleable = df[is_malleable].sample(n=n_samples,\n",
    "                         random_state=42)\n",
    "    not_malleable = df[~is_malleable].sample(n=n_samples, \n",
    "                         random_state=42)\n",
    "    df_balanced = pd.concat([malleable, not_malleable])\n",
    "    # shuffle the dataframe\n",
    "    df_balanced = df_balanced.sample(frac=1).reset_index(drop=True)\n",
    "    return df_balanced\n",
    "\n",
    "n_samples_train = 500\n",
    "n_samples_test = 100\n",
    "op_train = make_balanced_dataset(original_posts_train,  \n",
    "                                             n_samples_train // 2)\n",
    "\n",
    "op_test = make_balanced_dataset(original_posts_test, \n",
    "                                             n_samples_test // 2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-27T13:19:21.490625Z",
     "start_time": "2024-09-27T13:19:21.422909Z"
    }
   },
   "id": "c448de9e5f2ef3d6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMV: The anger and vitriol towards Unidan is overdramatic\n",
      "I belive that everyone is naturally extroverted. CMV\n"
     ]
    }
   ],
   "source": [
    "for a,b in op_train[:2].iterrows():\n",
    "    print(b['title'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-27T13:19:21.491230Z",
     "start_time": "2024-09-27T13:19:21.466087Z"
    }
   },
   "id": "811c75c5f28edaa2"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def create_jsonl(df, filename, prefix):\n",
    "    with open(filename, 'w') as f:\n",
    "        for idx, row in df.iterrows():\n",
    "            prompt = prefix + f\"{row['title']} + \\n + {row['selftext']}\"\n",
    "            request_content = {\n",
    "            \"custom_id\" : f\"request={idx}\",\n",
    "            \"method\" : \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \n",
    "                     \"messages\": [{\"role\": \"user\", \n",
    "                                   \"content\": prompt}\n",
    "                                  ],\n",
    "                     \"max_tokens\": 1000},\n",
    "            }\n",
    "            json.dump(request_content, f)\n",
    "            f.write('\\n')\n",
    "\n",
    "prefix = \"You're a semantic analyst. Now I will show you a person's opinion statement. We know that the person publicly announced his/her argument and encouraged other people to challenge it. Judging from the following context, do you think he/she is resistant or malleable to persuasion? Answer only with 'malleable' or 'resistant'. \\n text: \\n\" \n",
    "\n",
    "create_jsonl(op_train, 'op_train.jsonl', prefix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-27T13:19:23.926063Z",
     "start_time": "2024-09-27T13:19:21.476258Z"
    }
   },
   "id": "67dc237f034d4dd3"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "api_key = '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'\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "batch_input_file = client.files.create(\n",
    "  file=open(\"op_train.jsonl\", \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-27T13:19:27.457399Z",
     "start_time": "2024-09-27T13:19:23.925172Z"
    }
   },
   "id": "f02ac414ef772fff"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Billing hard limit has been reached', 'type': 'invalid_request_error', 'param': None, 'code': 'billing_hard_limit_reached'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mBadRequestError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m batch_input_file_id \u001B[38;5;241m=\u001B[39m batch_input_file\u001B[38;5;241m.\u001B[39mid\n\u001B[0;32m----> 3\u001B[0m client\u001B[38;5;241m.\u001B[39mbatches\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[1;32m      4\u001B[0m     input_file_id\u001B[38;5;241m=\u001B[39mbatch_input_file_id,\n\u001B[1;32m      5\u001B[0m     endpoint\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/v1/chat/completions\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      6\u001B[0m     completion_window\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m24h\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      7\u001B[0m     metadata\u001B[38;5;241m=\u001B[39m{\n\u001B[1;32m      8\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnightly eval job\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      9\u001B[0m     }\n\u001B[1;32m     10\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/openai/resources/batches.py:96\u001B[0m, in \u001B[0;36mBatches.create\u001B[0;34m(self, completion_window, endpoint, input_file_id, metadata, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;241m*\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     62\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[1;32m     63\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Batch:\n\u001B[1;32m     64\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    Creates and executes a batch from an uploaded file of requests\u001B[39;00m\n\u001B[1;32m     66\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001B[39;00m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post(\n\u001B[1;32m     97\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/batches\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     98\u001B[0m         body\u001B[38;5;241m=\u001B[39mmaybe_transform(\n\u001B[1;32m     99\u001B[0m             {\n\u001B[1;32m    100\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompletion_window\u001B[39m\u001B[38;5;124m\"\u001B[39m: completion_window,\n\u001B[1;32m    101\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mendpoint\u001B[39m\u001B[38;5;124m\"\u001B[39m: endpoint,\n\u001B[1;32m    102\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_file_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: input_file_id,\n\u001B[1;32m    103\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: metadata,\n\u001B[1;32m    104\u001B[0m             },\n\u001B[1;32m    105\u001B[0m             batch_create_params\u001B[38;5;241m.\u001B[39mBatchCreateParams,\n\u001B[1;32m    106\u001B[0m         ),\n\u001B[1;32m    107\u001B[0m         options\u001B[38;5;241m=\u001B[39mmake_request_options(\n\u001B[1;32m    108\u001B[0m             extra_headers\u001B[38;5;241m=\u001B[39mextra_headers, extra_query\u001B[38;5;241m=\u001B[39mextra_query, extra_body\u001B[38;5;241m=\u001B[39mextra_body, timeout\u001B[38;5;241m=\u001B[39mtimeout\n\u001B[1;32m    109\u001B[0m         ),\n\u001B[1;32m    110\u001B[0m         cast_to\u001B[38;5;241m=\u001B[39mBatch,\n\u001B[1;32m    111\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:1268\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1254\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1255\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1256\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1263\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1264\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1265\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1266\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1267\u001B[0m     )\n\u001B[0;32m-> 1268\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest(cast_to, opts, stream\u001B[38;5;241m=\u001B[39mstream, stream_cls\u001B[38;5;241m=\u001B[39mstream_cls))\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:945\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    942\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    943\u001B[0m     retries_taken \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 945\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request(\n\u001B[1;32m    946\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m    947\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m    948\u001B[0m     stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[1;32m    949\u001B[0m     stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[1;32m    950\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[1;32m    951\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:1049\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1046\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m   1048\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1049\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1051\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[1;32m   1052\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m   1053\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1057\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[1;32m   1058\u001B[0m )\n",
      "\u001B[0;31mBadRequestError\u001B[0m: Error code: 400 - {'error': {'message': 'Billing hard limit has been reached', 'type': 'invalid_request_error', 'param': None, 'code': 'billing_hard_limit_reached'}}"
     ]
    }
   ],
   "source": [
    "batch_input_file_id = batch_input_file.id\n",
    "\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"nightly eval job\"\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-27T13:19:28.272440Z",
     "start_time": "2024-09-27T13:19:27.458253Z"
    }
   },
   "id": "79c0fa66191e45cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "69a03815dbdf6e2a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
