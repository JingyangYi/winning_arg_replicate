{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-02T16:40:02.868098Z",
     "start_time": "2024-10-02T16:39:56.788369Z"
    }
   },
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 8000 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model_original, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth 2024.9.post3: Fast Llama patching. Transformers = 4.45.1.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti SUPER. Max memory: 15.688 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.1+cu124. CUDA = 8.9. CUDA Toolkit = 12.4.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:204: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:205: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:206: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:204: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:205: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:206: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T16:40:04.366301Z",
     "start_time": "2024-10-02T16:40:02.868967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model_original,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ],
   "id": "6bca8ffd85870808",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.9.post3 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T16:40:27.913726Z",
     "start_time": "2024-10-02T16:40:27.680580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "knowledge = \"Hints: 1. Reply Length: Longer replies tend to be more persuasive, as they can convey more information and elaborate on points effectively. 2. Language Dissimilarity with Original Post: Persuasive replies use different content words but match in stopwords. 3. Links and Evidence: Including links as evidence in an argument increases the chances of persuasion. 4. Calmer Tone: Replies that use calmer, less intense language are more likely to persuade, as they come across as more composed. 5. Positive Emotion and Sentiment: Persuasive replies include a mix of positive and negative sentiment.\"\n",
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs       = examples[\"input\"]\n",
    "    outputs      = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "\n",
    "def formatting_prompts_with_knowledge(examples):\n",
    "     examples[\"instruction\"] = [ins + \"\\n\" + knowledge for ins in examples[\"instruction\"]]\n",
    "     return formatting_prompts(examples)\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"json\", data_files={\"train\": \"pairs_train_alpaca.jsonl\",\n",
    "                                           \"test\": \"pairs_test_alpaca.jsonl\",})\n",
    "\n",
    "dataset_train = dataset[\"train\"]\n",
    "dataset_train = dataset_train.map(formatting_prompts_with_knowledge, batched=True)"
   ],
   "id": "ba05e90c1a140a89",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "164c5c829dc446b6a30b31e83d3af02f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T16:40:29.098057Z",
     "start_time": "2024-10-02T16:40:29.095068Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_train[0]",
   "id": "452de0765906feb1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Original Post:\\nCMV: Anything that is man-made is natural.\\nI can\\'t remember the topic that spurred this discussion, but a friend and I were debating whether man-made things were natural. He took the position that they are unnatural. \\n\\nHe cited this definition by Merriam-Webster:  existing in nature and not made or caused by people : coming from nature (http://www.merriam-webster.com/dictionary/natural) as his basis for the distinction for natural vs. unnatural.\\n\\nHowever, I respectfully disagree with his position and furthermore that definition of natural. People arise from nature. Humankind\\'s capacity to create, problem-solve, analyze, rationalize, and build also come from natural processes. How are the things we create unnatural? It is only through natural occurrences that we have this ability, why is it that we would give the credit of these things solely to man, as opposed to nature? We are not separate from nature, thus, how can any of our actions or creations be unnatural? If we were somehow separate from nature, I would understand the distinction between natural and man-made. However, I think unnatural and man-made are not synonyms by any means. It seems to me that man-made things MUST be natural due to our being part of nature. \\n\\nI would love to hear your arguments and to have my view changed if I am mistaken in my logic somewhere along the line.\\n\\nFirst Reply:\\nYou\\'re using natural to mean definition 8\\n\\n&gt;the universe, with all its phenomena. \\n\\nhttp://dictionary.reference.com/browse/nature\\n\\n&gt;The more common definition is definition 1.\\n\\n\"the material world, especially as surrounding humankind and existing independently of human activities. \"\\n\\nSo by definition we are not part of nature, as nature is more commonly used, and is in this sense used, to refer to things that exist independently of human activities.\\n\\nAnd before you mention the word independent.\\n\\nhttp://dictionary.reference.com/browse/independent?s=t\\n\\n\"not influenced or controlled by others in matters of opinion, conduct, etc.; thinking or acting for oneself: \"\\n\\nJust, say, breathing air that humans breathed isn\\'t enough.\\nSecond Reply:\\nLook at the definition you provided, if we remove the exclusion of things which humans create:\\n\\n&gt; existing in nature ~~and not made or caused by people~~\\n\\nSo essentially, by this definition, \"natural things\" are \"things that exist,\" which is frankly rather meaningless. If one wanted to discuss the results of human activity we would then have to make up a new word which could be redefined by the same argument. \\n\\nThe whole point of the word is to exclude human activity. If you remove that aspect, it simply ceases to have meaning.',\n",
       " 'output': 'second',\n",
       " 'instruction': \"This is a conversation from an online discussion community. The first was a poster who posted an opinion, and the next two replies were each trying to convince the poster to revise his opinion. The two responses were similar, but one managed to convince the poster and the other didn't. Now judge which response succeeded in persuading. Answer first or second onlyã€‚\\nHints: 1. Reply Length: Longer replies tend to be more persuasive, as they can convey more information and elaborate on points effectively. 2. Language Dissimilarity with Original Post: Persuasive replies use different content words but match in stopwords. 3. Links and Evidence: Including links as evidence in an argument increases the chances of persuasion. 4. Calmer Tone: Replies that use calmer, less intense language are more likely to persuade, as they come across as more composed. 5. Positive Emotion and Sentiment: Persuasive replies include a mix of positive and negative sentiment.\",\n",
       " 'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nThis is a conversation from an online discussion community. The first was a poster who posted an opinion, and the next two replies were each trying to convince the poster to revise his opinion. The two responses were similar, but one managed to convince the poster and the other didn\\'t. Now judge which response succeeded in persuading. Answer first or second onlyã€‚\\nHints: 1. Reply Length: Longer replies tend to be more persuasive, as they can convey more information and elaborate on points effectively. 2. Language Dissimilarity with Original Post: Persuasive replies use different content words but match in stopwords. 3. Links and Evidence: Including links as evidence in an argument increases the chances of persuasion. 4. Calmer Tone: Replies that use calmer, less intense language are more likely to persuade, as they come across as more composed. 5. Positive Emotion and Sentiment: Persuasive replies include a mix of positive and negative sentiment.\\n\\n### Input:\\nOriginal Post:\\nCMV: Anything that is man-made is natural.\\nI can\\'t remember the topic that spurred this discussion, but a friend and I were debating whether man-made things were natural. He took the position that they are unnatural. \\n\\nHe cited this definition by Merriam-Webster:  existing in nature and not made or caused by people : coming from nature (http://www.merriam-webster.com/dictionary/natural) as his basis for the distinction for natural vs. unnatural.\\n\\nHowever, I respectfully disagree with his position and furthermore that definition of natural. People arise from nature. Humankind\\'s capacity to create, problem-solve, analyze, rationalize, and build also come from natural processes. How are the things we create unnatural? It is only through natural occurrences that we have this ability, why is it that we would give the credit of these things solely to man, as opposed to nature? We are not separate from nature, thus, how can any of our actions or creations be unnatural? If we were somehow separate from nature, I would understand the distinction between natural and man-made. However, I think unnatural and man-made are not synonyms by any means. It seems to me that man-made things MUST be natural due to our being part of nature. \\n\\nI would love to hear your arguments and to have my view changed if I am mistaken in my logic somewhere along the line.\\n\\nFirst Reply:\\nYou\\'re using natural to mean definition 8\\n\\n&gt;the universe, with all its phenomena. \\n\\nhttp://dictionary.reference.com/browse/nature\\n\\n&gt;The more common definition is definition 1.\\n\\n\"the material world, especially as surrounding humankind and existing independently of human activities. \"\\n\\nSo by definition we are not part of nature, as nature is more commonly used, and is in this sense used, to refer to things that exist independently of human activities.\\n\\nAnd before you mention the word independent.\\n\\nhttp://dictionary.reference.com/browse/independent?s=t\\n\\n\"not influenced or controlled by others in matters of opinion, conduct, etc.; thinking or acting for oneself: \"\\n\\nJust, say, breathing air that humans breathed isn\\'t enough.\\nSecond Reply:\\nLook at the definition you provided, if we remove the exclusion of things which humans create:\\n\\n&gt; existing in nature ~~and not made or caused by people~~\\n\\nSo essentially, by this definition, \"natural things\" are \"things that exist,\" which is frankly rather meaningless. If one wanted to discuss the results of human activity we would then have to make up a new word which could be redefined by the same argument. \\n\\nThe whole point of the word is to exclude human activity. If you remove that aspect, it simply ceases to have meaning.\\n\\n### Response:\\nsecond<|end_of_text|>'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T16:40:34.841137Z",
     "start_time": "2024-10-02T16:40:33.025112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset_train,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "            per_device_train_batch_size = 2,\n",
    "            gradient_accumulation_steps = 4,\n",
    "            warmup_steps = 5,\n",
    "            # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "            max_steps = 60,\n",
    "            learning_rate = 2e-4,\n",
    "            fp16 = not is_bfloat16_supported(),\n",
    "            bf16 = is_bfloat16_supported(),\n",
    "            logging_steps = 1,\n",
    "            optim = \"adamw_8bit\",\n",
    "            weight_decay = 0.01,\n",
    "            lr_scheduler_type = \"linear\",\n",
    "            seed = 3407,\n",
    "            output_dir = \"outputs\",\n",
    "        ),\n",
    ")"
   ],
   "id": "104d11bcb3508937",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "231a0662157c4f73b6e88bb54e16a2f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T16:48:58.754549Z",
     "start_time": "2024-10-02T16:40:34.841798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer_stats = trainer.train()"
   ],
   "id": "3a586de8ab665366",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,000 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 60\n",
      " \"-____-\"     Number of trainable parameters = 41,943,040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 08:15, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.458500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.445900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.551600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.640200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.493800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.191700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.157200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.090700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.006500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.844400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.799200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.776800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.819400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.884400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.900400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.797400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.746200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.958700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.767000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.852200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.805100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.665100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.920200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.820400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.826200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.890700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.767000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.891800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.890600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.988200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.796300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.911100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.683400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.730400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.836700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.940800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.863700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.829300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.735700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.712100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.922900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.703100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.815400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.770800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>2.041500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.871600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.829900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.898800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.883600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.745800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.686700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.667900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.888700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.856800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.816700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.913800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.791200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.817000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T16:50:54.509433Z",
     "start_time": "2024-10-02T16:48:58.755255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "def infer(dataset, model, instruction):\n",
    "  results = []\n",
    "  for line in tqdm(dataset, desc=\"Inferring on test set: \"):\n",
    "      inputs = tokenizer(\n",
    "      [\n",
    "          alpaca_prompt.format(\n",
    "              instruction, # instruction\n",
    "              line[\"input\"], # input\n",
    "              \"\") # output - leave this blank for generation!\n",
    "      ], return_tensors = \"pt\").to(\"cuda\")\n",
    "      outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
    "      result = tokenizer.batch_decode(outputs)[0]\n",
    "\n",
    "      start_marker = \"### Response:\\n\"\n",
    "      end_marker = \"<|end_of_text|>\"\n",
    "      result = result[result.find(start_marker) + len(start_marker):\n",
    "                      result.find(end_marker)]\n",
    "\n",
    "      results.append(result)\n",
    "  return results\n",
    "\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "FastLanguageModel.for_inference(model_original)\n",
    "\n",
    "instruction = test_dataset[0][\"instruction\"]\n",
    "original_instruction = instruction\n",
    "\n",
    "benchmark_results = infer(test_dataset, model_original, original_instruction)\n",
    "ft_results = infer(test_dataset, model, instruction)"
   ],
   "id": "7e4134f1b716edec",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferring on test set: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:57<00:00,  3.45it/s]\n",
      "Inferring on test set: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:57<00:00,  3.46it/s]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T16:50:54.515490Z",
     "start_time": "2024-10-02T16:50:54.509896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "targets = [line[\"output\"][:1] for line in test_dataset]\n",
    "\n",
    "def accuracy(results, targets):\n",
    "    results = [result.lower()[:1] for result in results]\n",
    "    def check_pred(preds):\n",
    "        n_mismatches = 0\n",
    "        for i, p in (enumerate(preds)):\n",
    "            if p not in ['f', 's']:\n",
    "                if p not in ['m', 'r']:\n",
    "                    n_mismatches += 1\n",
    "        if n_mismatches:\n",
    "            print(f\"{n_mismatches}/{len(preds)} \"\n",
    "              f\"of the predictions are not in correct format! \"\n",
    "              f\"They will not be included in counting accuracy.\")\n",
    "        return n_mismatches\n",
    "    n_mismatches = check_pred(results)\n",
    "    \n",
    "    correct_count = 0\n",
    "    total = len(results)\n",
    "    for i in range(total):\n",
    "      if results[i] == targets[i]:\n",
    "        correct_count += 1\n",
    "\n",
    "    return (correct_count - n_mismatches) / (total - n_mismatches)\n",
    "\n",
    "accu_bm = accuracy(benchmark_results, targets)\n",
    "accu_ft = accuracy(ft_results, targets)\n",
    "print(f\"The original model accuracy on test set is {accu_bm:.3f}\")\n",
    "print(f\"The finetuned model accuracy on test set is {accu_ft:.3f}\")"
   ],
   "id": "a18fb1eb41eda88e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original model accuracy on test set is 0.540\n",
      "The finetuned model accuracy on test set is 0.530\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f06b67425927d1a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
